相对于第二版的主要改进点:
    1.根据不同的行业的加载不同的同义词列表，对从Mysql里拉来的数据进行扩充，目前的效果是1:4。同时也达到了分行业积累数据的目的
    2.模型算法调整为CNN+Attention的机制，该模型在三星客服项目中测试较为苛刻的情况下，准确率有1%的提升
    3.针对第二个版本的bug修复记录:
        (1).重新训练的时候数据可能变化，需要重新载入mysql数据
        (2).重新训练完成进度条100%，但是模型载入期间用户问问题打不上，修改为将模型载入后才将进度条设置为100%

改进的原理:
	1.字典树切词，多叉树遍历实现扩充。
	2.Attention机制在NLP多个领域均有较好的表现。

使用方法:
	cd server
	python3 run_server.py -u 2 -m ../data/runs/test1 -p 1111 -i 2 --log 1
	参数解释:
		log会将扩充后的数据写入data/log.txt文件，据此调整同义词词表
		i是指定行业，0是通用，1是汽车，2是银行
		m是训练模型保存地址
		u是mysql数据库id


测试方法:
	cd server
	python3 http_test.py
	输入:l 代表查询训练进度
	输入:t 代表重新训练
	输入:c 代表对话

	
修改记录:
	1.每次对话的时候要求有准确率的阈值，如果太高会让用户的问题过不去，如果太低，深度学习会拦截导致闲聊无法命中。
	因此本次修改，计算每次原始问题都答对的最低概率值A，和闲聊问题90%都不会拦截的概率值B。
	如果A>B，则选择B,这样就不存在问题了。
	如果B大于A，那么会选择A，此时就只能尽可能的放走闲聊，但不能保证90%.此类问题只会出现在数据量很少的数据集合中。
	
	最好的解决办法:建议整理100条左右的常用闲聊数据，放入到深度学习中，由深度学习完成闲聊功能。
	
	2.新增1500组同义词，数据增强的效果是1:10
	3.新增基于知识图谱的网络表示学习:DeepWalk和Node2vec，见文件nrl
	4.新增日志模块，按日期生成新的日志文件，日志文件存储在--module_path下的log文件夹里
	5.新增http接口控制log开关，获取模块版本号